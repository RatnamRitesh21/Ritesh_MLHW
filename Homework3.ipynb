{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNIhB+qvv3FUjBL77oE4Tdy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RatnamRitesh21/Ritesh_MLHW/blob/main/Homework3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6oSez4gCCZYJ"
      },
      "outputs": [],
      "source": [
        "from matplotlib import pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.ensemble import AdaBoostClassifier, BaggingClassifier, RandomForestClassifier\n",
        "from sklearn import impute, tree\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# reading the Test and Train data\n",
        "# We use read.csv to load the data\n",
        "data = pd.read_csv(\"train.csv\")\n",
        "test_data = pd.read_csv(\"test.csv\")\n",
        "test_data = test_data.drop([\"Name\", \"Ticket\",\"Cabin\"], axis=1)\n",
        "print(data)\n",
        "\n",
        "# Step1 : Preprocess the data\n",
        "# Here we are using the SimpleImputer function from sklearn to fill the empty columns in Age and Embarked columns\n",
        "# We are using most_frequent strategy to fill these columns with the frequent values\n",
        "imputer = SimpleImputer(strategy='most_frequent')\n",
        "data['Age'] = imputer.fit_transform(data['Age'].values.reshape(-1, 1)).ravel()\n",
        "print(imputer.fit_transform(data['Age'].values.reshape(-1, 1)).shape)\n",
        "print(imputer.fit_transform(data['Embarked'].values.reshape(-1, 1)).shape)\n",
        "data['Embarked'] = imputer.fit_transform(data['Embarked'].values.reshape(-1, 1)).ravel()\n",
        "\n",
        "\n",
        "# We are using the LabelEncoder function to encode the Sex and Embarked Columns\n",
        "# this encoder will assign the numerical values to the columns,such as 0,1,2\n",
        "encoder = LabelEncoder()\n",
        "data['Sex'] = encoder.fit_transform(data['Sex'])\n",
        "data['Embarked'] = encoder.fit_transform(data['Embarked'])\n",
        "data = data.drop([\"Name\",\"Ticket\",\"Cabin\"], axis=1)\n",
        "print(data)\n",
        "\n",
        "# Step 2: Feature Selection\n",
        "# Here we are first selecting few useful features from the columns thaare suitable to get the acurate DT\n",
        "# We are now performing feature selection, from these feature using the feature_importance function\n",
        "# this function selects the features whose importance is >0.04\n",
        "features = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Embarked']\n",
        "X = data.drop([\"Survived\"], axis=1)\n",
        "Y = data['Survived']\n",
        "random_forest = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "random_forest.fit(X,Y)\n",
        "feature_importances = random_forest.feature_importances_\n",
        "selected_features = [features[i] for i in range(len(features)) if feature_importances[i] > 0.04]\n",
        "X_train= X[selected_features]\n",
        "\n",
        "# Build the decision tree using the inbuilt function, the max depth parameter determines the size of the tree\n",
        "DT = tree.DecisionTreeClassifier(max_depth=3)\n",
        "# Train the Decision Tree classifier using the training data\n",
        "DT.fit(X_train, Y)\n",
        "# plotting the decision tree\n",
        "tree.plot_tree(DT,class_names = ['Survived','Not Survived'])\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# In the below code we use the same logic to preprocess the test data\n",
        "features = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Embarked']\n",
        "imputer = SimpleImputer(strategy='most_frequent')\n",
        "test_data['Age'] = imputer.fit_transform(test_data['Age'].values.reshape(-1, 1)).ravel()\n",
        "print(imputer.fit_transform(test_data['Age'].values.reshape(-1, 1)).shape)\n",
        "print(imputer.fit_transform(test_data['Embarked'].values.reshape(-1, 1)).shape)\n",
        "test_data['Embarked'] = imputer.fit_transform(test_data['Embarked'].values.reshape(-1, 1)).ravel()\n",
        "\n",
        "# We are using the LabelEncoder function to encode the Sex and Embarked Columns\n",
        "# this encoder will assign the numerical values to the columns,such as 0,1,2\n",
        "encoder = LabelEncoder()\n",
        "test_data['Sex'] = encoder.fit_transform(test_data['Sex'])\n",
        "test_data['Embarked'] = encoder.fit_transform(test_data['Embarked'])\n",
        "print(test_data)\n",
        "test1_data=test_data[selected_features]\n",
        "\n",
        "# Here we are predicting the values using the test data\n",
        "# we are using the predict function on the fine tuned decision tree\n",
        "classified_val = DT.predict(test1_data)\n",
        "classified_data = pd.DataFrame({\"PassengerId\":test_data.PassengerId,\"Survived\":classified_val})\n",
        "print(classified_data)\n",
        "\n",
        "# Step 4 : 5 fold cross validation on DT\n",
        "# Performing CrossValidation and finding the accuracy of the DT classifier\n",
        "# Here we are using the cross_val_score function to perform the validation\n",
        "cv_scores = cross_val_score(DT, X, Y, cv=5, scoring='accuracy')\n",
        "averageDT_accuracy = cv_scores.mean()\n",
        "print(\"Average Decision Tree Accuracy:\", averageDT_accuracy)\n",
        "\n",
        "# Step 5: Cross valication on Randon forest\n",
        "# Performing cross validation of Randomforest Classifier, and caliculating the accuracy\n",
        "random_forest = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "random_forest.fit(X,Y)\n",
        "cv_scores1 = cross_val_score(random_forest, X, Y, cv=5, scoring='accuracy')\n",
        "averageRF_accuracy = cv_scores1.mean()\n",
        "print(\"Average Random Forest Accuracy:\", averageRF_accuracy)\n",
        "\n",
        "\n",
        "# Question 4: 6)Which algorithm is better, Decision Tree or Random Forest?\n",
        "# Ans) Clearly, in my opinion, random forests outperform decision trees\n",
        "# because they amalgamate multiple decision trees to generate independent trees\n",
        "# that exhibit greater diversity and increased efficiency compared to individual decision trees at each branching point.\n",
        "\n",
        "\n",
        "# Question 4: 7)What are your observations and conclusions from the algorithm comparison and analysis?\n",
        "# Upon implementing both algorithms,\n",
        "# I observed that the random classifier achieved higher accuracy than the decision tree.\n",
        "#  Furthermore, the performance evaluation, which involved cross-validation in this instance,\n",
        "# provided a more comprehensive understanding of the accuracy levels for both models, namely Decision Trees and Random Forest.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Question 5 : Bagging Classifier\n",
        "\n",
        "bagging_classifier = BaggingClassifier(tree.DecisionTreeClassifier(random_state=42), n_estimators=200, random_state=42)\n",
        "bagging_classifier.fit(X,Y)\n",
        "# Apply cross-validation to estimate the average classification accuracy\n",
        "cv_scores_bagging = cross_val_score(bagging_classifier, X, Y, cv=5, scoring='accuracy')\n",
        "average_accuracy_bagging = cv_scores_bagging.mean()\n",
        "print(\"Average Bagging Accuracy:\", average_accuracy_bagging)\n",
        "\n",
        "\n",
        "#Question 6: Adaboost classifier\n",
        "\n",
        "adaboost_classifier = AdaBoostClassifier(tree.DecisionTreeClassifier(random_state=42), n_estimators=200, random_state=42,learning_rate=0.5)\n",
        "adaboost_classifier.fit(X,Y)\n",
        "# Apply cross-validation to estimate the average classification accuracy\n",
        "cv_scores_adaboost = cross_val_score(adaboost_classifier, X, Y, cv=5, scoring='accuracy')\n",
        "average_accuracy_adaboost = cv_scores_adaboost.mean()\n",
        "print(\"Average AdaBoost Accuracy:\", average_accuracy_adaboost)\n",
        "\n"
      ]
    }
  ]
}